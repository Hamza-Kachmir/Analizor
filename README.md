# Analizor

Une application web de d√©monstration pour un pipeline de donn√©es (ETL) interactif, d√©velopp√©e avec Python, Pandas, SQL et Docker.

---

### üöÄ Contexte du Projet

Ce projet a √©t√© r√©alis√© dans le cadre de mon admission √† une formation de **Data Engineer**. L'objectif √©tait de d√©montrer la ma√Ætrise des √©tapes fondamentales d'un pipeline de donn√©es.

**Analizor** est donc une d√©monstration technique de ce processus de bout en bout : r√©cup√©rer des donn√©es brutes de sources externes, les nettoyer et les structurer, les charger dans une base de donn√©es, puis les analyser pour en extraire des informations pertinentes.

### üõ†Ô∏è √Ä propos de cette d√©mo interactive

Cette application web a √©t√© cr√©√©e pour rendre ce processus technique visible et interactif. Plut√¥t que de simplement ex√©cuter un script en arri√®re-plan, l'interface vous guide √† travers chaque √©tape du pipeline, vous permettant de voir les donn√©es √©voluer en temps r√©el.

Le pipeline se d√©roule en 4 √©tapes contr√¥l√©es par l'utilisateur :

1.  **√âtape 1 : Extract (Extraction)**
    Les donn√©es brutes sur les produits, magasins et ventes sont t√©l√©charg√©es depuis des fichiers CSV distants.

2.  **√âtape 2 : Transform (Transformation)**
    Les donn√©es sont nettoy√©es, les colonnes sont renomm√©es et r√©organis√©es √† l'aide de la librairie **Pandas** pour √™tre pr√™tes √† √™tre ins√©r√©es en base de donn√©es.

3.  **√âtape 3 : Load (Chargement)**
    Les donn√©es transform√©es sont charg√©es dans une base de donn√©es **SQLite**. Les tables sont cr√©√©es et peupl√©es.

4.  **√âtape 4 : Analysis & Reporting**
    Des requ√™tes **SQL** sont ex√©cut√©es sur la base de donn√©es pour calculer des indicateurs cl√©s (top des ventes, chiffre d'affaires...). Une fiche de synth√®se est alors g√©n√©r√©e et affich√©e.

---

### ‚öôÔ∏è Technologies Utilis√©es

* **Langage :** Python
* **Analyse de Donn√©es :** Pandas
* **Base de Donn√©es :** SQLite
* **Framework Web / UI :** NiceGUI
* **Conteneurisation :** Docker